# What You See Is What You Get: Attention-based Self-guided Automatic Unit Test Generation

This repo contains both the defect-triggering test case generated by our study along with the code used to run the experiment.

## Defect Detection

```bash
cd Detection
```

### Training the detection model

```bash
python run.py \
--output_dir saved_models \
    --model_name_or_path microsoft/unixcoder-base-nine \
    --do_train \
    --train_data_file ./dataset/train.csv \
    --eval_data_file ./dataset/valid.csv \
    --num_train_epochs 200 \
    --block_size 512 \
    --train_batch_size 16 \
    --eval_batch_size 256 \
    --learning_rate 2e-5 \
    --max_grad_norm 1.0 \
    --seed 42 2>&1
```

### Test the detection model in D4J

```bash
python run.py \
    --output_dir saved_models \
    --model_name_or_path microsoft/unixcoder-base-nine \
    --do_test \
    --test_data_file ./dataset/D4J.csv \
    --block_size 512 \
    --eval_batch_size 64 \
    --seed 42 2>&1
```

## Unit Test Generation

```bash
cd Trigger
```

### Install pastalib

```bash
pip install pastalib
```

### Initialize a pre-trained LLM
 
```python
from pastalib.pasta import PASTA 
from transformers import AutoModelForCausalLM,AutoTokenizer

# Initialize pre-trained LLM
model = AutoModelForCausalLM.from_pretrained("deepseek-ai/deepseek-coder-6.7b-instruct", trust_remote_code=True, device_map='auto', torch_dtype=torch.bfloat16)
tokenizer = AutoTokenizer.from_pretrained("deepseek-ai/deepseek-coder-6.7b-instruct", trust_remote_code=True)

# Select the attention heads to be steered, 
# following the format of {'layer_id': [head_ids]}: 
head_config = {
    "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 18, 19, 23, 25, 28]
}

# Initialize the PASTA steerer
pasta = PASTA(
    model=model,
    tokenizer=tokenizer,
    head_config=head_config, 
    alpha=0.01, # scaling coefficient
    scale_position="exclude", # downweighting unselected tokens
)
```

### Select defective statements to emphasize, and then run inference as normal.

```bash
python inference.py --dataset ./data/RWB.csv
```

## Evaluation 

```bash
cd Evaluation
```

### Checkout Defects4J versions

```bash
cd scripts
bash checkout_d4j.sh
```

After performing `checkout` on all desired bugs, run the following scripts to add "compilable" snapshots from Defects4J prefix/postfix commits:
```bash 
cd data/D4J
bash tag_pre_fix_compilable.sh
bash tag_post_fix_compilable.sh
```

### Write the generated test cases to the corresponding folder

```
├── Detection
    ├── ...
├── Trigger
    ├── ...
├── Evaluation
    ├── data
        ├── D4J
            ├── gen_tests
        ├── RWB
            ├── gen_tests
    ├── ...
```

### Get execution results for generated tests

```bash
python postprocess_d4j.py \
    --gen_test_dir ../data/D4J/gen_tests \
    --exp_name D4J
```